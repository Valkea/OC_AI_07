{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85f62893-0675-4590-a1d6-7e07e0e2c919",
   "metadata": {},
   "source": [
    "# Menu <a class=\"anchor\" id=\"menu\"></a>\n",
    "   \n",
    "* [1. Préparatifs](#init)\n",
    "* [2. Recherche du `plongement` le plus adapté](#EMBEDDING)\n",
    "    * [2.1 Avec un embedding à `Zero`](#EMBEDDING_Zero)\n",
    "    * [2.2 Pretrained Word2Vec `word2vec-google-news-300`](#EMBEDDING_Word2Vec)\n",
    "    * [2.3 Pretrained FastText `fasttext-wiki-news-subwords-300`](#EMBEDDING_FastText)\n",
    "    * [2.4 Pretrained Glove `Stanford's GloVe 100d`](#EMBEDDING_glove6B100d)\n",
    "    * [2.5 Pretrained Glove `glove-twitter-25`](#EMBEDDING_glove25)\n",
    "    * [2.6 Pretrained Glove `glove-twitter-100`](#EMBEDDING_glove25)\n",
    "    * [2.7 Word2Vec `local training`](#EMBEDDING_Word2Vec_local)\n",
    "    * [2.8 FastText `local training`](#EMBEDDING_FastText_local)\n",
    "    * [2.9 Comparaison des scores](#EMBEDDING_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a1eb694-76ee-4986-a77e-5559cf2fc02f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pathlib\n",
    "import gzip\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding\n",
    "try:\n",
    "    from keras.utils import pad_sequences\n",
    "except ImportError:\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import joblib\n",
    "\n",
    "random_seed = 0\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# set random seed for keras reproductibility\n",
    "try:\n",
    "    keras.utils.set_random_seed(random_seed)\n",
    "except Exception:\n",
    "    tf.random.set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708cd824-8113-4ec4-b539-de6d715f3029",
   "metadata": {},
   "source": [
    "#### Définissons une fonction permettant de charger les embeddings pre-calculés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24792514-98aa-4baa-8e3e-a1813b052dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader as api\n",
    "\n",
    "def load_gensim_embedding(embedding_name, binary=False):\n",
    "    \n",
    "    embedding_path = pathlib.Path(pathlib.Path().absolute(), 'data', 'embedding_models', f'{embedding_name}.gz')\n",
    "    try:\n",
    "        if embedding_path.is_file():\n",
    "            print(f\"Loading from {embedding_path}\")\n",
    "            embedding_model = KeyedVectors.load_word2vec_format(embedding_path, binary=binary)\n",
    "        else:\n",
    "            print(\"Loading from the Git repos with API\")\n",
    "            embedding_model = api.load(embedding_name)\n",
    "            \n",
    "        return embedding_model\n",
    "    except Exception as e:\n",
    "        print(f\"The provided embedding model couldn't be loaded correctly: {e}\")\n",
    "        \n",
    "def load_trained_glove(embedding_name):\n",
    "    \n",
    "    def parse_file(file):\n",
    "        embeddings_index = {}\n",
    "        for line in file:\n",
    "            word, coefs = line.split(maxsplit=1)\n",
    "            coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "            embeddings_index[word] = coefs\n",
    "        return embeddings_index\n",
    "\n",
    "    try:\n",
    "        embedding_path = pathlib.Path(pathlib.Path().absolute(), 'data', 'embedding_models', f'{embedding_name}.gz')\n",
    "        if embedding_path.is_file():\n",
    "            print(f\"Loading from gZip: {embedding_path}\")\n",
    "            with gzip.open(embedding_path, mode='rt') as f:\n",
    "                return parse_file(f)\n",
    "        \n",
    "        embedding_path = pathlib.Path(pathlib.Path().absolute(), 'data', 'embedding_models', f'{embedding_name}.txt')\n",
    "        if embedding_path.is_file():\n",
    "            print(f\"Loading from TXT: {embedding_path}\")\n",
    "            with open(embedding_path) as f:\n",
    "                return parse_file(f)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"No such model found (it must be {embedding_name}.txt or {embedding_name}.gz)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"The provided embedding model couldn't be loaded correctly: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1627a2-c062-4b35-ad68-4ab2d52e7a51",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# 1. Préparatifs pour de la classification avec des réseaux de neurones <a class=\"anchor\" id=\"init\"></a> [⇪](#menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82af483-5d0e-460f-9880-309aeb612c37",
   "metadata": {},
   "source": [
    "#### Chargeons les fonctions de classification écrites sur les projets précédents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab00ce5c-fafb-4ba9-8d9e-f11e4b9faaef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from classification_utils import fit_model, get_scores, init_scores\n",
    "\n",
    "init_scores(\"data/scores_NN_SelectEmbedding.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3d41b7-615c-401f-ad29-7412c422f03f",
   "metadata": {},
   "source": [
    "#### Définissons les fonctions génériques de notre Spot Checking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "075a3b5d-7318-49e3-9e0b-9927723fcb16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f66e37-1a29-4432-a8fe-433ede056efb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def summarize_diagnostics(history):\n",
    "    \n",
    "    figure = plt.figure(figsize=(8,8))\n",
    "            \n",
    "    # plot loss\n",
    "    plt.subplot(211)\n",
    "    plt.title('Cross Entropy Loss')\n",
    "    plt.plot(history.history['loss'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_loss'], color='orange', label='val')\n",
    "    plt.legend()\n",
    "    \n",
    "    # plot accuracy\n",
    "    plt.subplot(212)\n",
    "    plt.title('Classification Accuracy')\n",
    "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_accuracy'], color='orange', label='val')\n",
    "    plt.legend()\n",
    "    \n",
    "    # save plot to file\n",
    "    #filename = sys.argv[0].split('/')[-1]\n",
    "    #plt.savefig(filename + '_plot.png')\n",
    "    #plt.close()\n",
    "    \n",
    "    plt.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29026961-9c65-47d5-bdca-15431202511f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_callbacks(model_name):\n",
    "\n",
    "    # Define savepoints\n",
    "    filepath = pathlib.Path(\"models\", f\"{model_name}.epoch{{epoch:02d}}-accuracy{{val_accuracy:.2f}}.hdf5\")\n",
    "\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        monitor=\"val_accuracy\",\n",
    "        mode=\"max\",\n",
    "        filepath=filepath,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    # Define EarlyStopping conditions\n",
    "    es = EarlyStopping(\n",
    "        monitor='val_loss', # 'binary_accuracy'\n",
    "        mode='min', # 'max'\n",
    "        patience=10,  # 6 because ReduceLROnPlateau is 5 \n",
    "        min_delta=0.01, \n",
    "        restore_best_weights=True, \n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    # Define Automatic LearningRate adjustments\n",
    "    lr_reducer = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        factor=0.1,\n",
    "        cooldown=5,\n",
    "        patience=5,\n",
    "        min_lr= 0.1e-5,\n",
    "        verbose=1,\n",
    "    )\n",
    "    \n",
    "    return [checkpoint, es, lr_reducer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d192d713-4230-4b00-9c18-b9cd57e97b29",
   "metadata": {
    "id": "d5becdef-5d03-4ac6-ba08-94715061dc51"
   },
   "source": [
    "#### Définissons une méthode de `cross-validation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f96b58a1-efd9-4df8-a6ff-9067a42ce858",
   "metadata": {
    "id": "bd3e09fc-72fa-4be3-9b2f-a48051235a2f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ba711c-804a-4578-9f10-fffd8905f83e",
   "metadata": {},
   "source": [
    "#### Définissons la taille de batch utilisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e65bcda8-8eb4-4040-ba29-613068542126",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32 # 8192 # 4096"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34678e6-adcc-4c88-9957-34edf2f6bf81",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# 2. Recherche du `plongement` le plus adapté <a class=\"anchor\" id=\"EMBEDDING\"></a> [⇪](#menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78b69c7-4112-4900-9b66-441de579b8b7",
   "metadata": {},
   "source": [
    "> https://fr.wikipedia.org/wiki/Word_embedding\n",
    ">\n",
    "> Pour utiliser les données en apprentissage machine, il est nécessaire de leur trouver une représentation mathématique, typiquement des vecteurs. Certaines données s'y prêtent directement, comme par exemple les images, qui engendrent des vecteurs riches en information, encodant toutes les nuances et les couleurs qui les composent. Les mots, quant à eux, sont des éléments d'information isolés, et certaines représentations rudimentaires se limitent à un simple identifiant par mot. Par exemple le mot « chat » sera encodé par un seul identifiant arbitraire, disons X87. C'est une représentation discrète, relativement pauvre, qui ne permet notamment pas de comparer deux mots entre eux5. Les plongements lexicaux, eux, représentent un mot par un vecteur. Par exemple, un chat sera représenté par le vecteur [0,43 0,88 0,98 1,3]. Si l'on encode tous les mots d'un dictionnaire ainsi, il devient alors **possible de comparer les vecteurs des mots entre eux**, par exemple en mesurant l'angle entre les vecteurs. Une bonne représentation de mots permettra alors de trouver que le mot « chien » est plus près du mot « chat » qu'il ne l'est du mot « gratte-ciel »6. Qui plus est, ces représentations permettent d'espérer que, dans l'espace vectoriel où le plongement est fait, on aura l'équation roi - homme + femme = reine ou encore l'équation Paris - France + Pologne = Varsovie7.\n",
    "> \n",
    "> Les plongements lexicaux sont également très **utiles pour mitiger le fléau de la dimension**, un problème récurrent en intelligence artificielle. Sans les plongements de mots, **les identifiants uniques représentant les mots engendrent des données éparses**, des points isolés dans un espace vaste et presque vide6. Avec les plongements de mots, en revanche, l'espace devient beaucoup plus restreint et il est plus facile pour un ordinateur d'y établir des regroupements, d'y découvrir des régularités, en apprentissage machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0115ebcf-69aa-48b8-84e1-ddb2f8777607",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def architecture01(f_opti, f_loss, f_metrics, embedding):\n",
    "        \n",
    "    inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "    \n",
    "    x = embedding(inputs)\n",
    "    x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "    x = layers.Dense(24, activation='relu')(x)\n",
    "    \n",
    "    predictions = layers.Dense(1, activation='sigmoid', name='predictions')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, predictions)\n",
    "    model.compile(loss=f_loss, optimizer=f_opti, metrics=f_metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33be42f3-16fb-4f33-aab8-74bdeb90be60",
   "metadata": {},
   "source": [
    "### Chargeons le jeu de données avec le PRE-PROCESSING sélectionné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47bd9cf5-da2b-4a4d-bf03-d73328b8eebf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>$ url$ - awww , that be a bummer . you shoulda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>be upset that he can not update his facebook b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I dive many time for the ball . manage to save...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feel itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>no , it be not behave at all . I be mad . why ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  $ url$ - awww , that be a bummer . you shoulda...\n",
       "1       0  be upset that he can not update his facebook b...\n",
       "2       0  I dive many time for the ball . manage to save...\n",
       "3       0      my whole body feel itchy and like its on fire\n",
       "4       0  no , it be not behave at all . I be mad . why ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1452791, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_work = pd.read_csv(\n",
    "    pathlib.Path(pathlib.Path().absolute(), 'data', 'data_nlp_1563108.csv'), \n",
    "    usecols=['target', 'lemmas_not_filtered'],\n",
    "    encoding='ISO-8859-1',\n",
    ")\n",
    "data_work.rename(columns={'lemmas_not_filtered':'text'}, inplace=True)\n",
    "display(data_work.head(), data_work.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cad184-80f9-4f1c-ba40-bcc61e5f7694",
   "metadata": {},
   "source": [
    "### Définissons une fonction permattant de Tokenizer notre jeu de données\n",
    "Nous avons établis que pour ce jeu de données il convient de choisir une tokenization avec environ 4500 mots retenus; c'est donc ce que nous allons faire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ba6e170-d1a6-46bb-8202-26af471de8a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data_RAW(X_train, X_test, tokenizer_num_words=4500, padding_size=50, verbose=1):\n",
    "    tokenizer = Tokenizer(num_words=tokenizer_num_words)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    dictionary = tokenizer.word_index\n",
    "    vocab_size = len(dictionary)+1 # Adding 1 because of reserved 0 index\n",
    "    \n",
    "    X_train_enc = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test_enc = tokenizer.texts_to_sequences(X_test)\n",
    "    \n",
    "    X_train_ready = pad_sequences(X_train_enc, padding='post', maxlen=padding_size)\n",
    "    X_test_ready = pad_sequences(X_test_enc, padding='post', maxlen=padding_size)\n",
    "    \n",
    "    # y_train = np.asarray(y_train).astype('float32').reshape((-1,1))\n",
    "    # y_test = np.asarray(y_test).astype('float32').reshape((-1,1))\n",
    "    \n",
    "    if verbose > 0:\n",
    "        print(\"----- One sample outputs for demo -----\")\n",
    "        print(f\">> Original sentence: {X_train.iloc[0]}\\n\")\n",
    "        print(f\">> Tokenized sentence: {tokenizer.sequences_to_texts(X_train_ready[:1])}\\n\")\n",
    "        print(f\">> X_train_enc: {X_train_enc[:1]}\\n\")\n",
    "        print(f\">> X_train_ready: {X_train_ready[:1]}\")\n",
    "        \n",
    "        print(f\"\\nVocab size: {vocab_size}\")\n",
    "    \n",
    "    return X_train_ready, X_test_ready, tokenizer, vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa391870-71ed-4484-8b6a-b181bd542ab4",
   "metadata": {},
   "source": [
    "### Définissons une fonction permettant d'entrainer le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2412a89-42fc-4ba6-92df-fd6145423691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(X_train_, X_test_, y_train_, y_test_, vocab_size_, embedding_layer_, preprocess_desc=\"\"):\n",
    "    \n",
    "    print(f\"Testing model with \\\"{preprocess_desc}\\\"\".upper().center(100,\"-\"), end='\\n\\n')\n",
    "    \n",
    "    # Embedding simple\n",
    "    #padding_size = 50\n",
    "    #embedding_dim = 100\n",
    "    #embedding = layers.Embedding(input_dim=vocab_size_, output_dim=embedding_dim, input_length=padding_size, trainable=True)\n",
    "    \n",
    "    # Prepare model\n",
    "    f_opti = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "    f_loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    f_metrics = ['accuracy'] # in this context 'accuracy' == keras.metrics.BinaryAccuracy()\n",
    "    \n",
    "    model = architecture01(f_opti, f_loss, f_metrics, embedding_layer_)\n",
    "    model.summary()\n",
    "    \n",
    "    t0 = time.perf_counter()\n",
    "    history = model.fit(\n",
    "        x=X_train_, y=y_train_, \n",
    "        validation_data=(X_test_, y_test_), \n",
    "        epochs=50, \n",
    "        batch_size=batch_size, \n",
    "        callbacks=init_callbacks(f\"archi01_PREPROCESS_{preprocess_desc}\"),\n",
    "        verbose=1,\n",
    "        # validation_split=0.2,\n",
    "        # train_labels\n",
    "    )\n",
    "    train_time = time.perf_counter() - t0\n",
    "    \n",
    "    # Print accuracy scores\n",
    "    loss, accuracy = model.evaluate(X_train_ready, y_train, verbose=False)\n",
    "    print(\"\\nTraining Accuracy: {:.4f}\".format(accuracy))\n",
    "    loss, accuracy = model.evaluate(X_test_ready, y_test, verbose=False)\n",
    "    print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "    \n",
    "    return history, model, train_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a823fbb2-83f2-4f44-969b-6bb5866a7fe4",
   "metadata": {},
   "source": [
    "### Divisons le jeu de données en `Train` et `Test` sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c014a22-fe0f-4555-8d75-0f3f32449694",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_work['text'], data_work.target, test_size=0.2, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b6279-611d-43e9-9953-e7ed23df73cc",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.1 Avec un embedding simple <a class=\"anchor\" id=\"EMBEDDING_Zero\"></a> [⇪](#menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffd2bda-5f24-49b4-948e-d26cc9898443",
   "metadata": {},
   "source": [
    "### Définissons une fonction permattant de Tokenizer notre jeu de données\n",
    "Nous avons établis que pour ce jeu de données il convient de choisir une tokenization avec environ 4500 mots retenus; c'est donc ce que nous allons faire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f405922-508e-4cba-9f6b-4c3129a4121d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data_RAW(X_train, X_test, tokenizer_num_words=4500, padding_size=50, verbose=1):\n",
    "    tokenizer = Tokenizer(num_words=tokenizer_num_words)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    dictionary = tokenizer.word_index\n",
    "    vocab_size = len(dictionary)+1 # Adding 1 because of reserved 0 index\n",
    "    \n",
    "    X_train_enc = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test_enc = tokenizer.texts_to_sequences(X_test)\n",
    "    \n",
    "    X_train_ready = pad_sequences(X_train_enc, padding='post', maxlen=padding_size)\n",
    "    X_test_ready = pad_sequences(X_test_enc, padding='post', maxlen=padding_size)\n",
    "    \n",
    "    # y_train = np.asarray(y_train).astype('float32').reshape((-1,1))\n",
    "    # y_test = np.asarray(y_test).astype('float32').reshape((-1,1))\n",
    "    \n",
    "    if verbose > 0:\n",
    "        print(\"----- One sample outputs for demo -----\")\n",
    "        print(f\">> Original sentence: {X_train.iloc[0]}\\n\")\n",
    "        print(f\">> Tokenized sentence: {tokenizer.sequences_to_texts(X_train_ready[:1])}\\n\")\n",
    "        print(f\">> X_train_enc: {X_train_enc[:1]}\\n\")\n",
    "        print(f\">> X_train_ready: {X_train_ready[:1]}\")\n",
    "        \n",
    "        print(f\"\\nVocab size: {vocab_size}\")\n",
    "    \n",
    "    return X_train_ready, X_test_ready, tokenizer, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b060269-81f8-41db-9cfe-e310f9ba8cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- One sample outputs for demo -----\n",
      ">> Original sentence: you too be fake .. :x ... disguise your link to be something else .\n",
      "\n",
      ">> Tokenized sentence: ['you too be fake x your link to be something else']\n",
      "\n",
      ">> X_train_enc: [[10, 46, 2, 1411, 197, 44, 456, 3, 2, 199, 447]]\n",
      "\n",
      ">> X_train_ready: [[  10   46    2 1411  197   44  456    3    2  199  447    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "\n",
      "Vocab size: 228026\n"
     ]
    }
   ],
   "source": [
    "X_train_ready, X_test_ready, tokenizer, vocab_size = preprocess_data_RAW(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1d67eb-5fa8-4887-9352-9d473ecf97dc",
   "metadata": {},
   "source": [
    "### Préparons l'embedding layer que nous allons utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e04f115-528a-4b89-b579-19f826cf8371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding simple\n",
    "padding_size = 50\n",
    "embedding_dim = 100\n",
    "embedding_layer = layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=padding_size, trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0547f9c9-a1a5-42ea-87d7-b64d519943c0",
   "metadata": {},
   "source": [
    "### Entrainons notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36fa990-4532-4f0f-b6fe-c0d921edd005",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history_BASE, model_BASE, train_time = train_model(X_train_ready, X_test_ready, y_train, y_test, vocab_size, embedding_layer, \"BASE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eff2ea-3341-4d2b-9d58-b8907c81fd88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:03.361739Z",
     "iopub.status.busy": "2022-08-02T18:13:03.361309Z",
     "iopub.status.idle": "2022-08-02T18:13:03.705789Z",
     "shell.execute_reply": "2022-08-02T18:13:03.704952Z",
     "shell.execute_reply.started": "2022-08-02T18:13:03.361712Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarize_diagnostics(history_BASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f912c66-dd96-4f80-9dda-868dabb10e84",
   "metadata": {},
   "source": [
    "### Affichons les scores du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd1d1fa6-a44d-47cc-84dc-0fc9af4aea62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:24.695574Z",
     "iopub.status.busy": "2022-08-02T18:13:24.695163Z",
     "iopub.status.idle": "2022-08-02T18:13:48.549293Z",
     "shell.execute_reply": "2022-08-02T18:13:48.548470Z",
     "shell.execute_reply.started": "2022-08-02T18:13:24.695534Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290559, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.perf_counter()\n",
    "y_preds_proba = model_BASE.predict(X_test_ready)\n",
    "# y_preds_proba = pd.Series([x[0] for x in y_preds_proba])\n",
    "\n",
    "y_preds = np.where(y_preds_proba > 0.5, 1,0)\n",
    "# y_preds = pd.Series([1 if x > 0.5 else 0 for x in y_preds_proba])\n",
    "inf_time = time.perf_counter() - t0\n",
    "\n",
    "y_preds_proba.shape\n",
    "y_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd695c62-7ab0-4e0c-aeef-0d5b09255da6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:48.551436Z",
     "iopub.status.busy": "2022-08-02T18:13:48.550997Z",
     "iopub.status.idle": "2022-08-02T18:13:50.511117Z",
     "shell.execute_reply": "2022-08-02T18:13:50.510384Z",
     "shell.execute_reply.started": "2022-08-02T18:13:48.551400Z"
    },
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1653231856185,
     "user": {
      "displayName": "Valkea",
      "userId": "01476199649418572392"
     },
     "user_tz": -120
    },
    "id": "81aba764-7f22-4ad1-b0ed-bc5b13f0b75e",
    "outputId": "e3c4ed78-a90b-46e0-baa0-c28f701f4414",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"NN Archi01 (BASE + Lemma_nof + Tokenizer4500)\"\n",
    "get_scores(model_name, y_pred=y_preds, y_pred_proba=y_preds_proba, register=True, X_ref=X_test_ready, y_ref=y_test, training_time=train_time, inference_time=inf_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80be3579-8815-4ff8-a896-4db27e52b5ad",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.2 Pretrained Word2Vec `word2vec-google-news-300` <a class=\"anchor\" id=\"EMBEDDING_Word2Vec\"></a> [⇪](#menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea7954-2157-4ab1-a5df-e733f521f372",
   "metadata": {},
   "source": [
    "### Préparons l'embedding layer que nous allons utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c6ec0997-1f9e-4ca3-8b45-25db17a12cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from /home/valkea/Dev/OpenClassrooms/Projets_AI/P7/data/embedding_models/word2vec-google-news-300.gz\n"
     ]
    }
   ],
   "source": [
    "em_model = load_gensim_embedding(\"word2vec-google-news-300\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a277c348-9667-4314-b8e9-14b552a04d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.10351562  0.13769531 -0.00297546 ...  0.04394531 -0.14550781\n",
      "  0.07128906]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=25)\n",
    "print(em_model.get_vector('like')) # Vector OK\n",
    "np.set_printoptions(threshold=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0562553d-09cb-4232-b320-8fa2387e8cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = em_model.vectors\n",
    "embedding_layer = Embedding(\n",
    "    input_dim=weights.shape[0],\n",
    "    output_dim=weights.shape[1],\n",
    "    weights=[weights],\n",
    "    trainable=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2a8d05-93d4-43f6-8127-6444b7c627f5",
   "metadata": {},
   "source": [
    "### Préparons le jeu de données avec l'embedding à tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63c4c554-64b2-4d51-9420-bedc345d5177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embedding_transform(embedding_model, sentences, max_len=65):\n",
    "\n",
    "    print('\\nPreparing the data with the provided embedding model...')\n",
    "    data = np.zeros([len(sentences), max_len], dtype=np.int32)\n",
    "    for i, (id,sentence) in enumerate(sentences.iteritems()):\n",
    "        for t, word in enumerate(sentence.split()):\n",
    "            if t == max_len:\n",
    "                break\n",
    "            if word in embedding_model.key_to_index:\n",
    "                data[i, t] = embedding_model.key_to_index[word]\n",
    "                \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8c127d2-a227-46b6-b219-4fe6b3879d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_embedding_demo(X_train, X_train_ready, index=0):\n",
    "    print(\"----- One sample outputs for demo -----\")\n",
    "    print(f\">> Original sentence: {X_train.iloc[index]}\\n\")\n",
    "    print(f\">> X_train_ready: {X_train_ready[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7680b3d3-51ac-4630-a140-a42722d19ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing the data with the provided embedding model...\n",
      "X_train_ready shape: (1162232, 50) y_train shape: (1162232,)\n",
      "\n",
      "Preparing the data with the provided embedding model...\n",
      "X_test_ready shape: (290559, 50) y_test shape: (290559,)\n"
     ]
    }
   ],
   "source": [
    "padding_size = 50\n",
    "\n",
    "X_train_ready = word_embedding_transform(em_model, X_train, padding_size)\n",
    "print('X_train_ready shape:', X_train_ready.shape, 'y_train shape:', y_train.shape)\n",
    "\n",
    "X_test_ready = word_embedding_transform(em_model, X_test, padding_size)\n",
    "print('X_test_ready shape:', X_test_ready.shape, 'y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "eb9e40e4-e438-4762-bb2a-3eb3abbcd946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- One sample outputs for demo -----\n",
      ">> Original sentence: you too be fake .. :x ... disguise your link to be something else .\n",
      "\n",
      ">> X_train_ready: [   30   213    38  4656   623     0    90 16758    54   211     5    38\n",
      "   252  1097     2     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0]\n"
     ]
    }
   ],
   "source": [
    "print_embedding_demo(X_train, X_train_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f744b63-7b02-4517-98f3-5abe02e94814",
   "metadata": {},
   "source": [
    "### Entrainons notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81e948b-e3ee-4f1f-abec-992724673154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history_W2V300, model_W2V300, train_time = train_model(X_train_ready, X_test_ready, y_train, y_test, vocab_size, embedding_layer, \"W2V300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aee484-7422-42b5-841e-e2d02d3ae93e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:03.361739Z",
     "iopub.status.busy": "2022-08-02T18:13:03.361309Z",
     "iopub.status.idle": "2022-08-02T18:13:03.705789Z",
     "shell.execute_reply": "2022-08-02T18:13:03.704952Z",
     "shell.execute_reply.started": "2022-08-02T18:13:03.361712Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarize_diagnostics(history_W2V300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a16aa6-ed0d-4c3a-91b0-48918c7a2ace",
   "metadata": {},
   "source": [
    "### Affichons les scores du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcc8a1c6-3336-421c-a3fe-eff1e3853347",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:24.695574Z",
     "iopub.status.busy": "2022-08-02T18:13:24.695163Z",
     "iopub.status.idle": "2022-08-02T18:13:48.549293Z",
     "shell.execute_reply": "2022-08-02T18:13:48.548470Z",
     "shell.execute_reply.started": "2022-08-02T18:13:24.695534Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290559, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.perf_counter()\n",
    "y_preds_proba = model_W2V300.predict(X_test_ready)\n",
    "# y_preds_proba = pd.Series([x[0] for x in y_preds_proba])\n",
    "\n",
    "y_preds = np.where(y_preds_proba > 0.5, 1,0)\n",
    "# y_preds = pd.Series([1 if x > 0.5 else 0 for x in y_preds_proba])\n",
    "inf_time = time.perf_counter() - t0\n",
    "\n",
    "y_preds_proba.shape\n",
    "y_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbabef97-31cb-44b9-ba97-35e668ffc619",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:48.551436Z",
     "iopub.status.busy": "2022-08-02T18:13:48.550997Z",
     "iopub.status.idle": "2022-08-02T18:13:50.511117Z",
     "shell.execute_reply": "2022-08-02T18:13:50.510384Z",
     "shell.execute_reply.started": "2022-08-02T18:13:48.551400Z"
    },
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1653231856185,
     "user": {
      "displayName": "Valkea",
      "userId": "01476199649418572392"
     },
     "user_tz": -120
    },
    "id": "81aba764-7f22-4ad1-b0ed-bc5b13f0b75e",
    "outputId": "e3c4ed78-a90b-46e0-baa0-c28f701f4414",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"NN Archi01 (PT_W2V_300 + Lemma_nof + Tokenizer4500)\"\n",
    "get_scores(model_name, y_pred=y_preds, y_pred_proba=y_preds_proba, register=True, X_ref=X_test_ready, y_ref=y_test, training_time=train_time, inference_time=inf_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360edc00-99d4-4029-8118-73aa9287c12e",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.3 Pretrained FastText `fasttext-wiki-news-subwords-300` <a class=\"anchor\" id=\"EMBEDDING_FastText\"></a> [⇪](#menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80e1122-ebfd-4306-a872-2111b9330a1b",
   "metadata": {},
   "source": [
    "### Préparons l'embedding layer que nous allons utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7a731a33-154e-44ec-b836-c28461beace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from /home/valkea/Dev/OpenClassrooms/Projets_AI/P7/data/embedding_models/fasttext-wiki-news-subwords-300.gz\n"
     ]
    }
   ],
   "source": [
    "em_model = load_gensim_embedding(\"fasttext-wiki-news-subwords-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5ac27dd4-a19a-460f-9692-afe3f6027bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0095372  0.01431    0.066626  ...  0.025587   0.010337  -0.03046  ]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=25)\n",
    "print(em_model.get_vector('like')) # Vector OK\n",
    "np.set_printoptions(threshold=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bf85fb29-9df9-4da4-a0af-fd505fe51453",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = em_model.vectors\n",
    "embedding_layer = Embedding(\n",
    "    input_dim=weights.shape[0],\n",
    "    output_dim=weights.shape[1],\n",
    "    weights=[weights],\n",
    "    trainable=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b40399-65f1-4809-8049-b285ed5d3b3e",
   "metadata": {},
   "source": [
    "### Préparons le jeu de données avec l'embedding à tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bf074957-4c4b-4aba-ae66-e00a92071f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing the data with the provided embedding model...\n",
      "X_train_ready shape: (1162232, 50) y_train shape: (1162232,)\n",
      "\n",
      "Preparing the data with the provided embedding model...\n",
      "X_test_ready shape: (290559, 50) y_test shape: (290559,)\n"
     ]
    }
   ],
   "source": [
    "padding_size = 50\n",
    "\n",
    "X_train_ready = word_embedding_transform(em_model, X_train, padding_size)\n",
    "print('X_train_ready shape:', X_train_ready.shape, 'y_train shape:', y_train.shape)\n",
    "\n",
    "X_test_ready = word_embedding_transform(em_model, X_test, padding_size)\n",
    "print('X_test_ready shape:', X_test_ready.shape, 'y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "603cfa60-ef09-48a9-bc4b-f6a6301f93ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- One sample outputs for demo -----\n",
      ">> Original sentence: you too be fake .. :x ... disguise your link to be something else .\n",
      "\n",
      ">> X_train_ready: [   30   213    38  4656   623     0    90 16758    54   211     5    38\n",
      "   252  1097     2     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0]\n"
     ]
    }
   ],
   "source": [
    "print_embedding_demo(X_train, X_train_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a29161-d27c-4386-b3b7-564660a122fe",
   "metadata": {},
   "source": [
    "### Entrainons notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0cf73d-f88e-4a4c-a5fd-9eec087ee98b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history_FT300, model_FT300, train_time = train_model(X_train_ready, X_test_ready, y_train, y_test, vocab_size, embedding_layer, \"FT300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b15f66f-3903-4dce-9e56-c27f1326fab9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:03.361739Z",
     "iopub.status.busy": "2022-08-02T18:13:03.361309Z",
     "iopub.status.idle": "2022-08-02T18:13:03.705789Z",
     "shell.execute_reply": "2022-08-02T18:13:03.704952Z",
     "shell.execute_reply.started": "2022-08-02T18:13:03.361712Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarize_diagnostics(history_FT300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d183cb55-b3d0-4965-9b19-4c4edbcad3f2",
   "metadata": {},
   "source": [
    "### Affichons les scores du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfa0f1df-5233-4950-a1ae-e69c4f570945",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:24.695574Z",
     "iopub.status.busy": "2022-08-02T18:13:24.695163Z",
     "iopub.status.idle": "2022-08-02T18:13:48.549293Z",
     "shell.execute_reply": "2022-08-02T18:13:48.548470Z",
     "shell.execute_reply.started": "2022-08-02T18:13:24.695534Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290559, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.perf_counter()\n",
    "y_preds_proba = model_FT300.predict(X_test_ready)\n",
    "# y_preds_proba = pd.Series([x[0] for x in y_preds_proba])\n",
    "\n",
    "y_preds = np.where(y_preds_proba > 0.5, 1,0)\n",
    "# y_preds = pd.Series([1 if x > 0.5 else 0 for x in y_preds_proba])\n",
    "inf_time = time.perf_counter() - t0\n",
    "\n",
    "y_preds_proba.shape\n",
    "y_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb315e73-4b6e-400c-aefb-61ea6db86240",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:48.551436Z",
     "iopub.status.busy": "2022-08-02T18:13:48.550997Z",
     "iopub.status.idle": "2022-08-02T18:13:50.511117Z",
     "shell.execute_reply": "2022-08-02T18:13:50.510384Z",
     "shell.execute_reply.started": "2022-08-02T18:13:48.551400Z"
    },
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1653231856185,
     "user": {
      "displayName": "Valkea",
      "userId": "01476199649418572392"
     },
     "user_tz": -120
    },
    "id": "81aba764-7f22-4ad1-b0ed-bc5b13f0b75e",
    "outputId": "e3c4ed78-a90b-46e0-baa0-c28f701f4414",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"NN Archi01 (PT_FT_300 + Lemma_nof + Tokenizer4500)\"\n",
    "get_scores(model_name, y_pred=y_preds, y_pred_proba=y_preds_proba, register=True, X_ref=X_test_ready, y_ref=y_test, training_time=train_time, inference_time=inf_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d938f5-60fd-4eec-b929-62a74c145107",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.4 Pretrained Glove `Stanford's GloVe 100d` <a class=\"anchor\" id=\"EMBEDDING_glove6B100d\"></a> [⇪](#menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637aaab7-ec46-438f-94d4-c8c749a1cdca",
   "metadata": {},
   "source": [
    "### Préparons le jeu de données avec l'embedding à tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85563bfa-79f6-49a6-a2c0-3c39958126d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 21:22:51.398789: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-03 21:22:51.398816: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-03 21:22:51.398839: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (valkea-XPS): /proc/driver/nvidia/version does not exist\n",
      "2022-08-03 21:22:51.400281: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "padding_size = 50\n",
    "\n",
    "try:\n",
    "    from tensorflow.keras.layers import TextVectorization\n",
    "except ImportError:\n",
    "    from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=4500, output_sequence_length=padding_size)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(X_train).batch(128)\n",
    "vectorizer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2e375c48-2872-4206-a115-f5aadac16d74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'i', 'be', 'to']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_vocabulary()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cd5ea165-6804-4811-89e4-a786681fbb0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   5,  495, 1619,   20,    5,    1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = vectorizer([[\"the cat sat on the mat\"]])\n",
    "output.numpy()[0, :6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e2bb08ef-a689-43d7-b4ee-30565e3227a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d5626d64-0124-42df-b22c-78a082119a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 21:28:35.219947: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 464892800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_ready shape: (1162232, 50) y_train shape: (1162232,)\n",
      "X_test_ready shape: (290559, 50) y_test shape: (290559,)\n"
     ]
    }
   ],
   "source": [
    "padding_size = 50\n",
    "\n",
    "X_train_ready = vectorizer(np.array([[s] for s in X_train])).numpy()\n",
    "print('X_train_ready shape:', X_train_ready.shape, 'y_train shape:', y_train.shape)\n",
    "y_train_ready = np.array(y_train)\n",
    "\n",
    "X_test_ready = vectorizer(np.array([[s] for s in X_test])).numpy()\n",
    "print('X_test_ready shape:', X_test_ready.shape, 'y_test shape:', y_test.shape)\n",
    "y_test_ready = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "77d46abf-78d2-40cd-9b21-fa0db47edf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- One sample outputs for demo -----\n",
      ">> Original sentence: you too be fake .. :x ... disguise your link to be something else .\n",
      "\n",
      ">> X_train_ready: [  11   48    3 1404  199    1   46  450    4    3  196  441    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print_embedding_demo(X_train, X_train_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1880b9c-d654-46a8-b0ad-822bdb365b9c",
   "metadata": {},
   "source": [
    "### Préparons l'embedding layer que nous allons utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e693ce4-25eb-46eb-8782-72b20878e394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from gZip: /home/valkea/Dev/OpenClassrooms/Projets_AI/P7/data/embedding_models/glove.6B.100d.gz\n"
     ]
    }
   ],
   "source": [
    "em_model = load_trained_glove(\"glove.6B.100d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63702945-505c-4847-92a5-f674d5b90596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.2687   0.81708  0.69896 ... -0.4011   0.74657  0.31122]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=25)\n",
    "print(em_model.get('like')) # Vector OK\n",
    "np.set_printoptions(threshold=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "88618159-92dd-4101-9fbc-6cf59350984a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 4333 words (167 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = em_model.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "749acfaf-8140-46b9-8198-6a8adf2bf2cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f7fbb6-1e9a-4c3a-a911-8778f9a5f078",
   "metadata": {},
   "source": [
    "### Entrainons notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15461e09-cdf0-42f0-951d-bdd2f460f920",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history_GL100, model_GL100, train_time = train_model(X_train_ready, X_test_ready, y_train_ready, y_test_ready, vocab_size, embedding_layer, \"GL100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbcd0fd-c08f-41ec-a9bb-0872af2054a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:03.361739Z",
     "iopub.status.busy": "2022-08-02T18:13:03.361309Z",
     "iopub.status.idle": "2022-08-02T18:13:03.705789Z",
     "shell.execute_reply": "2022-08-02T18:13:03.704952Z",
     "shell.execute_reply.started": "2022-08-02T18:13:03.361712Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarize_diagnostics(history_GL100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15088de9-297c-41a1-b6e5-3803bf9802d0",
   "metadata": {},
   "source": [
    "### Affichons les scores du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eba5724b-945b-4496-b618-3a2356c02ba3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:24.695574Z",
     "iopub.status.busy": "2022-08-02T18:13:24.695163Z",
     "iopub.status.idle": "2022-08-02T18:13:48.549293Z",
     "shell.execute_reply": "2022-08-02T18:13:48.548470Z",
     "shell.execute_reply.started": "2022-08-02T18:13:24.695534Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290559, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.perf_counter()\n",
    "y_preds_proba = model_GL100.predict(X_test_ready)\n",
    "# y_preds_proba = pd.Series([x[0] for x in y_preds_proba])\n",
    "\n",
    "y_preds = np.where(y_preds_proba > 0.5, 1,0)\n",
    "# y_preds = pd.Series([1 if x > 0.5 else 0 for x in y_preds_proba])\n",
    "inf_time = time.perf_counter() - t0\n",
    "\n",
    "y_preds_proba.shape\n",
    "y_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3cb52f-f5a7-4acb-99e7-cc45deb54672",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:48.551436Z",
     "iopub.status.busy": "2022-08-02T18:13:48.550997Z",
     "iopub.status.idle": "2022-08-02T18:13:50.511117Z",
     "shell.execute_reply": "2022-08-02T18:13:50.510384Z",
     "shell.execute_reply.started": "2022-08-02T18:13:48.551400Z"
    },
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1653231856185,
     "user": {
      "displayName": "Valkea",
      "userId": "01476199649418572392"
     },
     "user_tz": -120
    },
    "id": "81aba764-7f22-4ad1-b0ed-bc5b13f0b75e",
    "outputId": "e3c4ed78-a90b-46e0-baa0-c28f701f4414",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"NN Archi01 (PT_GL_100 + Lemma_nof + Tokenizer4500)\"\n",
    "get_scores(model_name, y_pred=y_preds, y_pred_proba=y_preds_proba, register=True, X_ref=X_test_ready, y_ref=y_test_ready, training_time=train_time, inference_time=inf_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841f7fac-7934-4615-bdde-5d957b245430",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.5 Pretrained Glove `glove-twitter-25` <a class=\"anchor\" id=\"EMBEDDING_glove25\"></a> [⇪](#menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d98a85-aa28-4960-9532-fa5ee749fbcd",
   "metadata": {},
   "source": [
    "### Préparons l'embedding layer que nous allons utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f48f2bc8-2dc8-480f-ae98-b463c8a669f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from /home/valkea/Dev/OpenClassrooms/Projets_AI/P7/data/embedding_models/glove-twitter-25.gz\n"
     ]
    }
   ],
   "source": [
    "em_model = load_gensim_embedding(\"glove-twitter-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "80dcb41b-73f1-4e62-8baf-035429d413e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.21063  -0.010992 -0.17552  ... -0.37547   0.58029   0.16067 ]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=25)\n",
    "print(em_model.get_vector('like')) # Vector OK\n",
    "np.set_printoptions(threshold=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1d302f1a-b338-460b-830a-4ffc56a41632",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = em_model.vectors\n",
    "embedding_layer = Embedding(\n",
    "    input_dim=weights.shape[0],\n",
    "    output_dim=weights.shape[1],\n",
    "    weights=[weights],\n",
    "    trainable=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b35c2ff-d22f-4c45-a74f-18a515121bad",
   "metadata": {},
   "source": [
    "### Préparons le jeu de données avec l'embedding à tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c87479a0-b477-440e-b148-e412cda4b6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing the data with the provided embedding model...\n",
      "X_train_ready shape: (1162232, 50) y_train shape: (1162232,)\n",
      "\n",
      "Preparing the data with the provided embedding model...\n",
      "X_test_ready shape: (290559, 50) y_test shape: (290559,)\n"
     ]
    }
   ],
   "source": [
    "padding_size = 50\n",
    "\n",
    "X_train_ready = word_embedding_transform(em_model, X_train, padding_size)\n",
    "print('X_train_ready shape:', X_train_ready.shape, 'y_train shape:', y_train.shape)\n",
    "\n",
    "X_test_ready = word_embedding_transform(em_model, X_test, padding_size)\n",
    "print('X_test_ready shape:', X_test_ready.shape, 'y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "febae56d-4f6a-4e64-863f-6b4e3ccace7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- One sample outputs for demo -----\n",
      ">> Original sentence: you too be fake .. :x ... disguise your link to be something else .\n",
      "\n",
      ">> X_train_ready: [   30   213    38  4656   623     0    90 16758    54   211     5    38\n",
      "   252  1097     2     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0]\n"
     ]
    }
   ],
   "source": [
    "print_embedding_demo(X_train, X_train_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6f9eff-70a3-438b-b8c1-c35dc1e6b3c6",
   "metadata": {},
   "source": [
    "### Entrainons notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2216db51-02f9-4795-8777-32a20d1d7cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history_GLT25, model_GLT25, train_time = train_model(X_train_ready, X_test_ready, y_train, y_test, vocab_size, embedding_layer, \"GLT25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e384e87b-587f-49ac-96e6-8f5e0e5632ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:03.361739Z",
     "iopub.status.busy": "2022-08-02T18:13:03.361309Z",
     "iopub.status.idle": "2022-08-02T18:13:03.705789Z",
     "shell.execute_reply": "2022-08-02T18:13:03.704952Z",
     "shell.execute_reply.started": "2022-08-02T18:13:03.361712Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarize_diagnostics(history_GL25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b078013-609c-4a86-8349-f8a18f7e74c3",
   "metadata": {},
   "source": [
    "### Affichons les scores du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "589514c8-d269-48b8-a5d2-2e13aa0c836c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:24.695574Z",
     "iopub.status.busy": "2022-08-02T18:13:24.695163Z",
     "iopub.status.idle": "2022-08-02T18:13:48.549293Z",
     "shell.execute_reply": "2022-08-02T18:13:48.548470Z",
     "shell.execute_reply.started": "2022-08-02T18:13:24.695534Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290559, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.perf_counter()\n",
    "y_preds_proba = model_GLT25.predict(X_test_ready)\n",
    "# y_preds_proba = pd.Series([x[0] for x in y_preds_proba])\n",
    "\n",
    "y_preds = np.where(y_preds_proba > 0.5, 1,0)\n",
    "# y_preds = pd.Series([1 if x > 0.5 else 0 for x in y_preds_proba])\n",
    "inf_time = time.perf_counter() - t0\n",
    "\n",
    "y_preds_proba.shape\n",
    "y_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bba9b6-4eb1-4549-a5a2-2567393fe677",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:48.551436Z",
     "iopub.status.busy": "2022-08-02T18:13:48.550997Z",
     "iopub.status.idle": "2022-08-02T18:13:50.511117Z",
     "shell.execute_reply": "2022-08-02T18:13:50.510384Z",
     "shell.execute_reply.started": "2022-08-02T18:13:48.551400Z"
    },
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1653231856185,
     "user": {
      "displayName": "Valkea",
      "userId": "01476199649418572392"
     },
     "user_tz": -120
    },
    "id": "81aba764-7f22-4ad1-b0ed-bc5b13f0b75e",
    "outputId": "e3c4ed78-a90b-46e0-baa0-c28f701f4414",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"NN Archi01 (PT_GLT_25 + Lemma_nof + Tokenizer4500)\"\n",
    "get_scores(model_name, y_pred=y_preds, y_pred_proba=y_preds_proba, register=True, X_ref=X_test_ready, y_ref=y_test, training_time=train_time, inference_time=inf_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeab03b9-e038-48f1-b257-a40fc6f50e58",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.6 Pretrained Glove `glove-twitter-100` <a class=\"anchor\" id=\"EMBEDDING_glove25\"></a> [⇪](#menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115a9f5e-37bc-4a9d-b838-4030dcbbb496",
   "metadata": {},
   "source": [
    "### Préparons l'embedding layer que nous allons utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c98501a4-ce41-4f69-80ff-ab72deafdea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from /home/valkea/Dev/OpenClassrooms/Projets_AI/P7/data/embedding_models/glove-twitter-100.gz\n"
     ]
    }
   ],
   "source": [
    "em_model = load_gensim_embedding(\"glove-twitter-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e97dc054-49a7-4057-a6af-fab4bb2296e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.21063  -0.010992 -0.17552  ... -0.37547   0.58029   0.16067 ]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=25)\n",
    "print(em_model.get_vector('like')) # Vector OK\n",
    "np.set_printoptions(threshold=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ee7b1b55-40b5-4d18-bd89-45313965395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = em_model.vectors\n",
    "embedding_layer = Embedding(\n",
    "    input_dim=weights.shape[0],\n",
    "    output_dim=weights.shape[1],\n",
    "    weights=[weights],\n",
    "    trainable=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9212f1-08aa-44e3-b7a5-1174efea597e",
   "metadata": {},
   "source": [
    "### Préparons le jeu de données avec l'embedding à tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "40e08aa2-1f54-47c3-b057-1075d2a5e716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing the data with the provided embedding model...\n",
      "X_train_ready shape: (1162232, 50) y_train shape: (1162232,)\n",
      "\n",
      "Preparing the data with the provided embedding model...\n",
      "X_test_ready shape: (290559, 50) y_test shape: (290559,)\n"
     ]
    }
   ],
   "source": [
    "padding_size = 50\n",
    "\n",
    "X_train_ready = word_embedding_transform(em_model, X_train, padding_size)\n",
    "print('X_train_ready shape:', X_train_ready.shape, 'y_train shape:', y_train.shape)\n",
    "\n",
    "X_test_ready = word_embedding_transform(em_model, X_test, padding_size)\n",
    "print('X_test_ready shape:', X_test_ready.shape, 'y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "765f43c9-a3c7-4e09-96f7-fca03fe73e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- One sample outputs for demo -----\n",
      ">> Original sentence: you too be fake .. :x ... disguise your link to be something else .\n",
      "\n",
      ">> X_train_ready: [   30   213    38  4656   623     0    90 16758    54   211     5    38\n",
      "   252  1097     2     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0]\n"
     ]
    }
   ],
   "source": [
    "print_embedding_demo(X_train, X_train_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecef66cf-c762-46aa-90f9-6d95e51bb130",
   "metadata": {},
   "source": [
    "### Entrainons notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47afd968-b547-4313-8506-98d92f27e99e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history_GLT100, model_GLT100, train_time = train_model(X_train_ready, X_test_ready, y_train, y_test, vocab_size, embedding_layer, \"GLT100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dacbd2-12ba-458d-9b9c-7daa3507e7fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:03.361739Z",
     "iopub.status.busy": "2022-08-02T18:13:03.361309Z",
     "iopub.status.idle": "2022-08-02T18:13:03.705789Z",
     "shell.execute_reply": "2022-08-02T18:13:03.704952Z",
     "shell.execute_reply.started": "2022-08-02T18:13:03.361712Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarize_diagnostics(history_GL100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933d3244-dfe1-457e-949d-fde2d4612e56",
   "metadata": {},
   "source": [
    "### Affichons les scores du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e950dca0-5ef4-41ec-a08a-215a008c50d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:24.695574Z",
     "iopub.status.busy": "2022-08-02T18:13:24.695163Z",
     "iopub.status.idle": "2022-08-02T18:13:48.549293Z",
     "shell.execute_reply": "2022-08-02T18:13:48.548470Z",
     "shell.execute_reply.started": "2022-08-02T18:13:24.695534Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290559, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.perf_counter()\n",
    "y_preds_proba = model_GLT100.predict(X_test_ready)\n",
    "# y_preds_proba = pd.Series([x[0] for x in y_preds_proba])\n",
    "\n",
    "y_preds = np.where(y_preds_proba > 0.5, 1,0)\n",
    "# y_preds = pd.Series([1 if x > 0.5 else 0 for x in y_preds_proba])\n",
    "inf_time = time.perf_counter() - t0\n",
    "\n",
    "y_preds_proba.shape\n",
    "y_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e645587-5d22-4a91-9947-324750bc6e75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:48.551436Z",
     "iopub.status.busy": "2022-08-02T18:13:48.550997Z",
     "iopub.status.idle": "2022-08-02T18:13:50.511117Z",
     "shell.execute_reply": "2022-08-02T18:13:50.510384Z",
     "shell.execute_reply.started": "2022-08-02T18:13:48.551400Z"
    },
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1653231856185,
     "user": {
      "displayName": "Valkea",
      "userId": "01476199649418572392"
     },
     "user_tz": -120
    },
    "id": "81aba764-7f22-4ad1-b0ed-bc5b13f0b75e",
    "outputId": "e3c4ed78-a90b-46e0-baa0-c28f701f4414",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"NN Archi01 (PT_GLT_100 + Lemma_nof + Tokenizer4500)\"\n",
    "get_scores(model_name, y_pred=y_preds, y_pred_proba=y_preds_proba, register=True, X_ref=X_test_ready, y_ref=y_test, training_time=train_time, inference_time=inf_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69269475-4148-465e-ac92-ef05f7f45f4c",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.7 Word2Vec `local training` <a class=\"anchor\" id=\"EMBEDDING_Word2Vec_local\"></a> [⇪](#menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2866a5-35c0-4eec-ae39-d6fb432cef10",
   "metadata": {},
   "source": [
    "### Préparons l'embedding layer que nous allons utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69d5ae43-ad0c-4abd-8cf5-5e12f7e0b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25c2bbaa-49d4-481b-8b42-f3516a69490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(X_train, vector_size=150, min_count=5, window=5, sg=0, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "256287c5-f2bc-4d73-a33b-1a10042e71da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (130, 256)\n"
     ]
    }
   ],
   "source": [
    "pretrained_weights = w2v_model.wv.vectors\n",
    "vocab_size, emdedding_size = pretrained_weights.shape\n",
    "print('Embedding shape:', pretrained_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f876b68c-005d-4fed-b22a-42aefc17f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = w2v_model.wv.vectors\n",
    "embedding_layer = Embedding(\n",
    "    input_dim=weights.shape[0],\n",
    "    output_dim=weights.shape[1],\n",
    "    weights=[weights],\n",
    "    trainable=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59592d9f-454e-4116-87c4-1274f29d89d3",
   "metadata": {},
   "source": [
    "#### Regardons un peu ce que notre modèle propose comme mots similaires pour quelques mots choisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b06d8c3-f349-428d-8e68-15176ff2dc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ good is not in the Word2Vec vocabulary\n",
      "⚠️ bad is not in the Word2Vec vocabulary\n",
      "⚠️ sad is not in the Word2Vec vocabulary\n",
      "⚠️ fabulous is not in the Word2Vec vocabulary\n",
      "⚠️ difficult is not in the Word2Vec vocabulary\n",
      "⚠️ easy is not in the Word2Vec vocabulary\n",
      "⚠️ boring is not in the Word2Vec vocabulary\n",
      "⚠️ fun is not in the Word2Vec vocabulary\n"
     ]
    }
   ],
   "source": [
    "for word in ['good', 'bad', 'sad', 'fabulous', 'difficult', 'easy', 'boring', 'fun']:\n",
    "    if word in w2v_model.wv:\n",
    "        most_similar = ', '.join('%s (%.2f)' % (similar, dist) for similar, dist in w2v_model.wv.most_similar(word)[:8])\n",
    "        print(f'{word.rjust(15)} -> {most_similar}')\n",
    "    else:\n",
    "        print(f'⚠️ {word} is not in the Word2Vec vocabulary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59257c8-3215-4421-9dc3-11c7139a7ed0",
   "metadata": {},
   "source": [
    "### Préparons le jeu de données avec l'embedding à tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "362921da-73b7-414e-8900-efe2101cea95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing the data with the provided embedding model...\n",
      "X_train_ready shape: (1162232, 50) y_train shape: (1162232,)\n",
      "\n",
      "Preparing the data with the provided embedding model...\n",
      "X_test_ready shape: (290559, 50) y_test shape: (290559,)\n"
     ]
    }
   ],
   "source": [
    "padding_size = 50\n",
    "\n",
    "X_train_ready = word_embedding_transform(w2v_model.wv, X_train, padding_size)\n",
    "print('X_train_ready shape:', X_train_ready.shape, 'y_train shape:', y_train.shape)\n",
    "\n",
    "X_test_ready = word_embedding_transform(w2v_model.wv, X_test, padding_size)\n",
    "print('X_test_ready shape:', X_test_ready.shape, 'y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28df89d9-7435-4f20-a48c-b0bf684cd8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- One sample outputs for demo -----\n",
      ">> Original sentence: you too be fake .. :x ... disguise your link to be something else .\n",
      "\n",
      ">> X_train_ready: [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 17  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0]\n"
     ]
    }
   ],
   "source": [
    "print_embedding_demo(X_train, X_train_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23d1795-44fb-46e4-81ef-3c76feaddc73",
   "metadata": {},
   "source": [
    "### Entrainons notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a31ec0-c928-463b-a593-e70a3f10c416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history_W2Vlocal, model_W2Vlocal, train_time = train_model(X_train_ready, X_test_ready, y_train, y_test, vocab_size, embedding_layer, \"W2Vlocal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396fd92f-ebe7-489f-8b92-0d058e2ae0c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:03.361739Z",
     "iopub.status.busy": "2022-08-02T18:13:03.361309Z",
     "iopub.status.idle": "2022-08-02T18:13:03.705789Z",
     "shell.execute_reply": "2022-08-02T18:13:03.704952Z",
     "shell.execute_reply.started": "2022-08-02T18:13:03.361712Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarize_diagnostics(history_W2Vlocal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46391519-7e03-4d98-8860-686fb25e17bd",
   "metadata": {},
   "source": [
    "### Affichons les scores du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41b46156-455c-4130-8534-f154837564e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:24.695574Z",
     "iopub.status.busy": "2022-08-02T18:13:24.695163Z",
     "iopub.status.idle": "2022-08-02T18:13:48.549293Z",
     "shell.execute_reply": "2022-08-02T18:13:48.548470Z",
     "shell.execute_reply.started": "2022-08-02T18:13:24.695534Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290559, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.perf_counter()\n",
    "y_preds_proba = model_W2Vlocal.predict(X_test_ready)\n",
    "# y_preds_proba = pd.Series([x[0] for x in y_preds_proba])\n",
    "\n",
    "y_preds = np.where(y_preds_proba > 0.5, 1,0)\n",
    "# y_preds = pd.Series([1 if x > 0.5 else 0 for x in y_preds_proba])\n",
    "inf_time = time.perf_counter() - t0\n",
    "\n",
    "y_preds_proba.shape\n",
    "y_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b15f63-01d8-492c-a97a-adbda215e26f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:48.551436Z",
     "iopub.status.busy": "2022-08-02T18:13:48.550997Z",
     "iopub.status.idle": "2022-08-02T18:13:50.511117Z",
     "shell.execute_reply": "2022-08-02T18:13:50.510384Z",
     "shell.execute_reply.started": "2022-08-02T18:13:48.551400Z"
    },
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1653231856185,
     "user": {
      "displayName": "Valkea",
      "userId": "01476199649418572392"
     },
     "user_tz": -120
    },
    "id": "81aba764-7f22-4ad1-b0ed-bc5b13f0b75e",
    "outputId": "e3c4ed78-a90b-46e0-baa0-c28f701f4414",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"NN Archi01 (W2V_150 + Lemma_nof + Tokenizer4500)\"\n",
    "get_scores(model_name, y_pred=y_preds, y_pred_proba=y_preds_proba, register=True, X_ref=X_test_ready, y_ref=y_test, training_time=train_time, inference_time=inf_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205a224a-c11e-476a-bf3b-64eaa821e03f",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.8 FastText `local training` <a class=\"anchor\" id=\"EMBEDDING_FastText_local\"></a> [⇪](#menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b9c860-243f-4522-b57c-b4d51b0a47d9",
   "metadata": {},
   "source": [
    "### Préparons l'embedding layer que nous allons utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e9e57de-9573-4b6d-95ea-fc838e865eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "081c8be1-0a12-45c1-a3e9-0181071bf996",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = FastText(X_train, vector_size=150, min_count=5, window=5, sg=0, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdac84c2-0218-4840-b6d6-8126d69e8545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (130, 150)\n"
     ]
    }
   ],
   "source": [
    "pretrained_weights = ft_model.wv.vectors\n",
    "vocab_size, emdedding_size = pretrained_weights.shape\n",
    "print('Embedding shape:', pretrained_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "689adee6-b81e-4e8c-a666-12787f767715",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = ft_model.wv.vectors\n",
    "embedding_layer = Embedding(\n",
    "    input_dim=weights.shape[0],\n",
    "    output_dim=weights.shape[1],\n",
    "    weights=[weights],\n",
    "    trainable=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25574309-5e98-4a44-af0e-9f17fb4289b8",
   "metadata": {},
   "source": [
    "#### Regardons un peu ce que notre modèle propose comme mots similaires pour quelques mots choisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "841b2d86-3315-4693-a057-8c6b2185be38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           good -> z (0.27), $ (0.18), & (0.15), < (0.12), ¹ (0.09), ¯ (0.09),  (0.09), ¸ (0.09)\n",
      "            bad ->  (0.20), & (0.17), u (0.15), % (0.14), m (0.12), ! (0.12), 2 (0.12), ~ (0.12)\n",
      "            sad -> « (0.13),  (0.12),  (0.12),  (0.12),  (0.12), $ (0.12),  (0.11), ¶ (0.10)\n",
      "       fabulous -> * (0.27), : (0.22), 5 (0.18), 6 (0.16), 7 (0.16), | (0.15), 9 (0.14), \\ (0.13)\n",
      "      difficult -> 1 (0.24), 4 (0.23), # (0.22), 8 (0.22), 2 (0.22), 9 (0.21), 6 (0.20), 7 (0.20)\n",
      "           easy -> < (0.16), w (0.13), t (0.12), l (0.12), * (0.10), , (0.09), ´ (0.09), ? (0.09)\n",
      "         boring -> ] (0.17), | (0.16), Ã (0.16), [ (0.15), } (0.15), { (0.14), \\ (0.14),  (0.13)\n",
      "            fun -> k (0.19), l (0.19), h (0.17), ) (0.12), ^ (0.12), e (0.10), I (0.09), a (0.09)\n"
     ]
    }
   ],
   "source": [
    "for word in ['good', 'bad', 'sad', 'fabulous', 'difficult', 'easy', 'boring', 'fun']:\n",
    "    if word in ft_model.wv:\n",
    "        most_similar = ', '.join('%s (%.2f)' % (similar, dist) for similar, dist in ft_model.wv.most_similar(word)[:8])\n",
    "        print(f'{word.rjust(15)} -> {most_similar}')\n",
    "    else:\n",
    "        print(f'⚠️ {word} is not in the Word2Vec vocabulary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19e10e3-e66f-42ea-a664-75812ac6a673",
   "metadata": {},
   "source": [
    "### Préparons le jeu de données avec l'embedding à tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c362c0a-a7ad-4cde-a141-e6befd34831d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing the data with the provided embedding model...\n",
      "X_train_ready shape: (1162232, 50) y_train shape: (1162232,)\n",
      "\n",
      "Preparing the data with the provided embedding model...\n",
      "X_test_ready shape: (290559, 50) y_test shape: (290559,)\n"
     ]
    }
   ],
   "source": [
    "padding_size = 50\n",
    "\n",
    "X_train_ready = word_embedding_transform(ft_model.wv, X_train, padding_size)\n",
    "print('X_train_ready shape:', X_train_ready.shape, 'y_train shape:', y_train.shape)\n",
    "\n",
    "X_test_ready = word_embedding_transform(ft_model.wv, X_test, padding_size)\n",
    "print('X_test_ready shape:', X_test_ready.shape, 'y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "956898f6-ea3b-49ae-8b20-a867db914990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- One sample outputs for demo -----\n",
      ">> Original sentence: you too be fake .. :x ... disguise your link to be something else .\n",
      "\n",
      ">> X_train_ready: [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 17  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0]\n"
     ]
    }
   ],
   "source": [
    "print_embedding_demo(X_train, X_train_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d365e30-c7b8-4ba4-87d2-d913ac211e2a",
   "metadata": {},
   "source": [
    "### Entrainons notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f621a04-443a-4fbf-91f5-7c9ef44310a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history_FTlocal, model_FTlocal, train_time = train_model(X_train_ready, X_test_ready, y_train, y_test, vocab_size, embedding_layer, \"FTlocal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e52bf3-ad46-48a7-be94-a8881c26e155",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:03.361739Z",
     "iopub.status.busy": "2022-08-02T18:13:03.361309Z",
     "iopub.status.idle": "2022-08-02T18:13:03.705789Z",
     "shell.execute_reply": "2022-08-02T18:13:03.704952Z",
     "shell.execute_reply.started": "2022-08-02T18:13:03.361712Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarize_diagnostics(history_FTlocal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c764493-acc1-4b41-88a4-4c88f93413c6",
   "metadata": {},
   "source": [
    "### Affichons les scores du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2ceae65-e3d1-4ff2-bb05-838a8e9bf88b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:24.695574Z",
     "iopub.status.busy": "2022-08-02T18:13:24.695163Z",
     "iopub.status.idle": "2022-08-02T18:13:48.549293Z",
     "shell.execute_reply": "2022-08-02T18:13:48.548470Z",
     "shell.execute_reply.started": "2022-08-02T18:13:24.695534Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290559, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.perf_counter()\n",
    "y_preds_proba = model_FTlocal.predict(X_test_ready)\n",
    "# y_preds_proba = pd.Series([x[0] for x in y_preds_proba])\n",
    "\n",
    "y_preds = np.where(y_preds_proba > 0.5, 1,0)\n",
    "# y_preds = pd.Series([1 if x > 0.5 else 0 for x in y_preds_proba])\n",
    "inf_time = time.perf_counter() - t0\n",
    "\n",
    "y_preds_proba.shape\n",
    "y_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d20303-a5e7-4cf6-a9ce-12960e12c595",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2022-08-02T18:13:48.551436Z",
     "iopub.status.busy": "2022-08-02T18:13:48.550997Z",
     "iopub.status.idle": "2022-08-02T18:13:50.511117Z",
     "shell.execute_reply": "2022-08-02T18:13:50.510384Z",
     "shell.execute_reply.started": "2022-08-02T18:13:48.551400Z"
    },
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1653231856185,
     "user": {
      "displayName": "Valkea",
      "userId": "01476199649418572392"
     },
     "user_tz": -120
    },
    "id": "81aba764-7f22-4ad1-b0ed-bc5b13f0b75e",
    "outputId": "e3c4ed78-a90b-46e0-baa0-c28f701f4414",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"NN Archi01 (FT_150 + Lemma_nof + Tokenizer4500)\"\n",
    "get_scores(model_name, y_pred=y_preds, y_pred_proba=y_preds_proba, register=True, X_ref=X_test_ready, y_ref=y_test, training_time=train_time, inference_time=inf_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152943d1-b3c2-4f2a-b2dd-a32bab84c417",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.9 Comparaison des scores <a class=\"anchor\" id=\"EMBEDDING_scores\"></a> [⇪](#menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9105c492-9d18-48bb-b5cd-1e080fadcce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f47073-92bd-48e2-b4f5-97d8fe2ac675",
   "metadata": {},
   "source": [
    ">#### Conclusion de la sélection du plongement:\n",
    "> TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137d6ee6-ad1e-4809-89da-091667366f62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d43b0d-1d49-48c9-a6cf-2dfa6b497d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fd6e07e-5595-42f8-9e2c-9ab450784bfd",
   "metadata": {},
   "source": [
    "----\n",
    "----\n",
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "raw",
   "id": "02e76e42-2a56-4a63-80e7-8228198e4e65",
   "metadata": {},
   "source": [
    "em_model = load_gensim_embedding(\"glove-twitter-25\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26b2dc2c-3c96-4467-a5e6-5eb87577494c",
   "metadata": {},
   "source": [
    "em_model.most_similar(positive=['fruit', 'flower'], topn=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "19d2e668-fb82-418a-82e2-539700cc744d",
   "metadata": {},
   "source": [
    "em_model.get_vector('like') # Vector OK"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ba688a2-d1e1-4aa7-8c9e-bd04a025fe48",
   "metadata": {},
   "source": [
    "em_model.get_vector('likexxx') # Error OK"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e35d4c5a-d715-40da-b10f-44a7e59448f4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "c938d47e-7a83-4540-bc11-983584a051a6",
   "metadata": {},
   "source": [
    "em_model_100 = load_gensim_embedding(\"glove-twitter-100\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "acbb6708-b625-44dd-a8d9-359a50b938b0",
   "metadata": {},
   "source": [
    "em_model_100.most_similar(positive=['fruit', 'flower'], topn=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "017c0e9d-b7a2-43a4-aa83-244433e6bdb9",
   "metadata": {},
   "source": [
    "em_model_100.get_vector('like') # Vector OK"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a3d62b0-0f86-48b6-a966-4ab0b03cb955",
   "metadata": {},
   "source": [
    "em_model_100.get_vector('likexxx') # Error OK"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cdd568bb-d409-4860-b33a-591031769ef9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "7fcd2b96-b978-4ac9-aa9c-fec863c5ce5c",
   "metadata": {},
   "source": [
    "em_model_ft = load_gensim_embedding(\"fasttext-wiki-news-subwords-300\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3409fc6a-2afc-4cc9-89ac-4d59f4a0bd80",
   "metadata": {},
   "source": [
    "em_model_ft.most_similar(positive=['fruit', 'flower'], topn=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75da0dfe-6667-4b49-bf3f-c6989adab5c2",
   "metadata": {},
   "source": [
    "em_model_ft.get_vector('like') # Vector OK"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d18a7190-3f0c-45dc-bbbd-b6c39541c11c",
   "metadata": {},
   "source": [
    "em_model_ft.get_vector('likexxx') # Error OK"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d4e5b752-2211-4d4f-8303-72b6ee78ccef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "1eff7423-d0e9-494a-83af-5728902964a8",
   "metadata": {},
   "source": [
    "em_model_w2v = load_gensim_embedding(\"word2vec-google-news-300\", binary=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7038e355-fe8f-468b-a3bb-694c8624f67c",
   "metadata": {},
   "source": [
    "em_model_w2v.most_similar(positive=['fruit', 'flower'], topn=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "06a6b0eb-4fc9-4fbd-9c0d-8c0adbec07a7",
   "metadata": {},
   "source": [
    "em_model_w2v.get_vector('like') # Vector OK"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cea55a28-d8e1-4edd-90b1-781b37daf12b",
   "metadata": {},
   "source": [
    "em_model_w2v.get_vector('likexxx') # Error OK"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a5fa2db-e097-4cfc-8a71-6ce8783ac1ce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "d2896891-ee4a-48d2-ae04-fd5b5614a8b4",
   "metadata": {},
   "source": [
    "em_model_gv100 = load_trained_glove(\"glove.6B.100d\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f9f5eae-bd94-4e88-b75b-c6c7c56e78c2",
   "metadata": {},
   "source": [
    "em_model_gv100.get('like') # Vector OK"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d88f95d-d6c9-400b-a6d1-1192751e05a7",
   "metadata": {},
   "source": [
    "em_model_gv100.get('likexxx') # No Error No return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf4c955-c221-4544-a46d-10ddbbf92ac0",
   "metadata": {},
   "source": [
    "----\n",
    "----\n",
    "----\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvP7",
   "language": "python",
   "name": "venvp7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
